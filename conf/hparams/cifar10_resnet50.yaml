# @package _global_
# changes hyper-parameters of model if resnet-50 used with cifar-10
# more info: https://hydra.cc/docs/patterns/specializing_config
model:
  num_classes: 10

hparams:
  epochs: 400
  batch_size: 64
  grad_clip_val: null # change to float to activate

  optimizer:
    _target_: torch.optim.SGD
    lr: 0.1
    weight_decay: 5e-4
    momentum: 0.1
    nesterov: true

  scheduler:
    _target_: torch.optim.lr_scheduler.MultiStepLR
    milestones: [160, 300, 360]
    gamma: 0.1
